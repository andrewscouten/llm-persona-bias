{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add38755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the dataset CSV file\n",
    "DATASET_PATH = \"../markedpersonas/data/gpt4_main_generations.csv\"\n",
    "\n",
    "# Pretrained model for sentiment analysis\n",
    "SENTIMENT_MODEL = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c52559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and configuration\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Loading PyTorch library...\")\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available:  {torch.cuda.is_available()}\\n\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Import transformers components\n",
    "print(\"Loading transformers library...\")\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aad2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will take a few minutes to run\n",
    "from cs7313.embeddings import EmbeddingExtractor\n",
    "\n",
    "extractor = EmbeddingExtractor(SENTIMENT_MODEL)\n",
    "embeddings = extractor(df[\"text\"].to_numpy())\n",
    "print(f\"Extracted embeddings shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5fa0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loading {SENTIMENT_MODEL} model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(SENTIMENT_MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(SENTIMENT_MODEL, output_attentions=True)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "id2label = model.config.id2label\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4203a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATASET_PATH)\n",
    "df = df.dropna(subset=[\"text\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4e2ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a698b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions: sentiment + attention-derived importance\n",
    "SPECIAL_IDS = set(tokenizer.all_special_ids)\n",
    "\n",
    "def run_model(text: str, max_length: int = 256):\n",
    "    \"\"\"Run the classifier and return sentiment, score, token list, token-level attention importance, and CLS embedding.\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_length, padding=False)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_attentions=True, output_hidden_states=True)\n",
    "    probs = torch.softmax(outputs.logits[0], dim=-1)\n",
    "    pred_idx = int(torch.argmax(probs).item())\n",
    "    pred_label = id2label[pred_idx]\n",
    "    pred_score = float(probs[pred_idx].item())\n",
    "    # Average heads on last layer and use CLS row as importance source\n",
    "    last_attn = outputs.attentions[-1].mean(dim=1)[0]  # seq x seq\n",
    "    cls_to_tokens = last_attn[0]  # attention from CLS token\n",
    "    cls_to_tokens = cls_to_tokens / cls_to_tokens.sum()\n",
    "    input_ids = inputs[\"input_ids\"][0].tolist()\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    importance = []\n",
    "    for tok, score, tok_id in zip(tokens, cls_to_tokens.tolist(), input_ids):\n",
    "        if tok_id in SPECIAL_IDS:\n",
    "            continue\n",
    "        importance.append((tok, score))\n",
    "    # CLS embedding for clustering\n",
    "    cls_embedding = outputs.hidden_states[-1][0, 0, :].detach().cpu().numpy()\n",
    "    return {\n",
    "        \"label\": pred_label,\n",
    "        \"score\": pred_score,\n",
    "        \"tokens\": tokens,\n",
    "        \"importance\": importance,\n",
    "        \"cls_embedding\": cls_embedding,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f040d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run sentiment + attention over a subset for speed\n",
    "N_EVAL = min(300, len(df))\n",
    "sample_df = df.sample(n=N_EVAL, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "sentiments = []\n",
    "scores = []\n",
    "importances = []\n",
    "emb_list = []\n",
    "\n",
    "for text in tqdm(sample_df[\"text\"], desc=\"Scoring\", total=len(sample_df)):\n",
    "    out = run_model(text)\n",
    "    sentiments.append(out[\"label\"])\n",
    "    scores.append(out[\"score\"])\n",
    "    importances.append(out[\"importance\"])\n",
    "    emb_list.append(out[\"cls_embedding\"])\n",
    "\n",
    "sample_df[\"sentiment\"] = sentiments\n",
    "sample_df[\"sentiment_score\"] = scores\n",
    "sample_df[\"importance\"] = importances\n",
    "sample_df[\"cls_embedding\"] = emb_list\n",
    "\n",
    "embeddings = np.vstack(emb_list)\n",
    "sample_df.head()[[c for c in [\"text\",\"sentiment\",\"sentiment_score\"] if c in sample_df.columns]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eedf38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', None)\n",
    "sample_df[sample_df[\"sentiment\"] == \"NEGATIVE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a0aa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate token importance across the sample\n",
    "from collections import Counter\n",
    "\n",
    "token_scores = Counter()\n",
    "for tok_scores in sample_df[\"importance\"]:\n",
    "    for tok, score in tok_scores:\n",
    "        token_scores[tok] += score\n",
    "\n",
    "top_tokens = token_scores.most_common(25)\n",
    "importance_df = pd.DataFrame(top_tokens, columns=[\"token\", \"importance\"])\n",
    "fig = px.bar(importance_df, x=\"importance\", y=\"token\", orientation=\"h\", title=\"Top tokens by attention importance\")\n",
    "fig.update_layout(height=600)\n",
    "fig.show()\n",
    "importance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11268259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention heatmap for a single example\n",
    "example_idx = 0\n",
    "example_text = sample_df.loc[example_idx, \"text\"]\n",
    "example_out = run_model(example_text)\n",
    "tokens = [tok for tok, _ in example_out[\"importance\"]]\n",
    "scores = [score for _, score in example_out[\"importance\"]]\n",
    "\n",
    "plt.figure(figsize=(max(12, len(tokens) * 0.4), 2.5))\n",
    "sns.heatmap(np.array([scores]), cmap=\"viridis\", cbar=True, xticklabels=tokens, yticklabels=[\"CLS â†’ token\"], vmin=0.0, vmax=max(scores) if scores else 1.0)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Last-layer attention from CLS to tokens\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939c23a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering the CLS embeddings to inspect geometry vs sentiment\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "\n",
    "print(\"Applying dimensionality reduction on CLS embeddings...\")\n",
    "tsne = TSNE(n_components=2, random_state=SEED, perplexity=30, max_iter=800)\n",
    "emb_tsne = tsne.fit_transform(embeddings)\n",
    "\n",
    "pca = PCA(n_components=2, random_state=SEED)\n",
    "emb_pca = pca.fit_transform(embeddings)\n",
    "\n",
    "reducer = umap.UMAP(n_components=2, random_state=SEED)\n",
    "emb_umap = reducer.fit_transform(embeddings)\n",
    "\n",
    "sample_df[\"tsne_x\"], sample_df[\"tsne_y\"] = emb_tsne[:,0], emb_tsne[:,1]\n",
    "sample_df[\"pca_x\"], sample_df[\"pca_y\"] = emb_pca[:,0], emb_pca[:,1]\n",
    "sample_df[\"umap_x\"], sample_df[\"umap_y\"] = emb_umap[:,0], emb_umap[:,1]\n",
    "\n",
    "fig = px.scatter(sample_df, x=\"umap_x\", y=\"umap_y\", color=\"sentiment\", hover_data=[\"sentiment_score\", \"text\"], title=\"UMAP of CLS embeddings colored by sentiment\", width=900, height=650)\n",
    "fig.update_traces(marker=dict(size=7, opacity=0.75))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9ba27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple identity marker probe: do attention scores spike when markers appear?\n",
    "identity_markers = [\n",
    "    \"woman\", \"man\", \"female\", \"male\", \"girl\", \"boy\",\n",
    "    \"black\", \"white\", \"asian\", \"latino\", \"arab\", \"indian\",\n",
    "    \"christian\", \"muslim\", \"jewish\", \"atheist\", \"gay\", \"queer\", \"trans\"\n",
    "]\n",
    "\n",
    "marker_rows = []\n",
    "for marker in identity_markers:\n",
    "    total_score = 0.0\n",
    "    mention_rows = 0\n",
    "    for text, tok_scores in zip(sample_df[\"text\"], sample_df[\"importance\"]):\n",
    "        lower_text = str(text).lower()\n",
    "        if marker in lower_text:\n",
    "            mention_rows += 1\n",
    "            for tok, score in tok_scores:\n",
    "                if marker in tok:\n",
    "                    total_score += score\n",
    "    marker_rows.append({\"marker\": marker, \"mentions\": mention_rows, \"token_importance\": total_score})\n",
    "marker_df = pd.DataFrame(marker_rows)\n",
    "marker_df = marker_df.sort_values(by=\"token_importance\", ascending=False)\n",
    "\n",
    "fig = px.bar(marker_df, x=\"token_importance\", y=\"marker\", orientation=\"h\", title=\"Attention mass on identity markers (higher = model focuses more)\", hover_data=[\"mentions\"])\n",
    "fig.update_layout(height=650)\n",
    "fig.show()\n",
    "marker_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e763f5e",
   "metadata": {},
   "source": [
    "# Notes and next steps\n",
    "- Raise `MAX_ROWS` / `N_EVAL` if you have GPU time to cover more generations.\n",
    "- Swap `SENTIMENT_MODEL` for domain-specific checkpoints if needed; ensure they expose attentions.\n",
    "- Add more identity markers or regex patterns to `identity_markers` for targeted probes.\n",
    "- For reproducibility run `pip install transformers datasets seaborn plotly umap-learn scikit-learn tqdm` in your environment before executing cells."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs7313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
