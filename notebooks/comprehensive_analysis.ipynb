{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cfa0d26",
   "metadata": {},
   "source": [
    "# Comprehensive Analysis of Embedding Space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0c7846",
   "metadata": {},
   "source": [
    "## Notebook Parameters\n",
    "\n",
    "Configure the analysis settings below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99e412ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose embeddings model from the list below:\n",
    "# https://huggingface.co/google-bert/bert-base-uncased\n",
    "# Model \t                            params \tLanguage\n",
    "# bert-base-uncased \t                110M \tEnglish\n",
    "# bert-large-uncased \t                340M \tEnglish\n",
    "# bert-base-cased \t                    110M \tEnglish\n",
    "# bert-large-cased \t                    340M \tEnglish\n",
    "# bert-base-chinese \t                110M \tChinese\n",
    "# bert-base-multilingual-cased \t        110M \tMultiple\n",
    "# bert-large-uncased-whole-word-masking 340M \tEnglish\n",
    "# bert-large-cased-whole-word-masking \t340M \tEnglish\n",
    "EMBEDDINGS_MODEL = \"bert-large-cased\"\n",
    "\n",
    "# Datasets to analyze\n",
    "DATASETS = {\n",
    "    'GPT-4': \"../markedpersonas/data/gpt4_main_generations.csv\",\n",
    "    'ChatGPT': \"../markedpersonas/data/chatgpt/chatgpt_main_generations.csv\",\n",
    "    'DaVinci-002': \"../markedpersonas/data/dv2/dv2_main_generations.csv\",\n",
    "    'DaVinci-003': \"../markedpersonas/data/dv3/dv3_main_generations.csv\",\n",
    "}\n",
    "\n",
    "# Clustering parameters\n",
    "N_CLUSTERS = 5          # For K-Means, Agglomerative, GMM\n",
    "DBSCAN_EPS = 0.5        # DBSCAN epsilon parameter\n",
    "DBSCAN_MIN_SAMPLES = 5  # DBSCAN minimum samples\n",
    "\n",
    "# Random seed for reproducibility\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d8c2dc",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import required libraries and configure the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "247bf089",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "201ae79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PyTorch library...\n",
      "PyTorch version: 2.9.1+rocm6.4\n",
      "CUDA available:  True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Loading PyTorch library...\")\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available:  {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eb002d",
   "metadata": {},
   "source": [
    "## Load All Datasets\n",
    "\n",
    "Load all available markedpersonas datasets and examine their structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6bd6a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GPT-4: 1350 samples\n",
      "Columns: ['Unnamed: 0.3', 'Unnamed: 0.2', 'Unnamed: 0.1', 'Unnamed: 0', 'text', 'prompt_num', 'model', 'gender', 'race', 'prompt']\n",
      "Loaded ChatGPT: 1650 samples\n",
      "Columns: ['Unnamed: 0.3', 'Unnamed: 0.2', 'Unnamed: 0.1', 'Unnamed: 0', 'text', 'prompt_num', 'model', 'gender', 'race', 'prompt']\n",
      "Loaded DaVinci-002: 900 samples\n",
      "Columns: ['Unnamed: 0', 'text', 'model', 'gender', 'race', 'prompt']\n",
      "Loaded DaVinci-003: 1350 samples\n",
      "Columns: ['Unnamed: 0.1', 'Unnamed: 0', 'text', 'model', 'gender', 'race', 'prompt', 'prompt_num']\n",
      "\n",
      "Total datasets loaded: 4\n"
     ]
    }
   ],
   "source": [
    "# Load all datasets\n",
    "dataframes = {}\n",
    "for name, path in DATASETS.items():\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        dataframes[name] = df\n",
    "        print(f\"Loaded {name}: {len(df)} samples\")\n",
    "        print(f\"Columns: {list(df.columns)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {name}: {e}\")\n",
    "\n",
    "print(f\"\\nTotal datasets loaded: {len(dataframes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa05debe",
   "metadata": {},
   "source": [
    "## Prepare Data for Analysis\n",
    "\n",
    "Create hover text and combine datasets for comparative analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cd2aa78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset shape: (5250, 13)\n",
      "\n",
      "Dataset distribution:\n",
      "dataset\n",
      "ChatGPT        1650\n",
      "GPT-4          1350\n",
      "DaVinci-003    1350\n",
      "DaVinci-002     900\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Add hover text and model labels to each dataset\n",
    "for name, df in dataframes.items():\n",
    "    df['hover_text'] = df['text'].apply(lambda x: str(x)[:200] + '...' if len(str(x)) > 200 else str(x))\n",
    "    df['dataset'] = name\n",
    "    \n",
    "    # Create demographic label if available\n",
    "    if 'gender' in df.columns and 'race' in df.columns:\n",
    "        df['demographic'] = df['gender'].astype(str) + ' - ' + df['race'].astype(str)\n",
    "\n",
    "# Create combined dataset for cross-model analysis\n",
    "combined_df = pd.concat(dataframes.values(), ignore_index=True)\n",
    "print(f\"Combined dataset shape: {combined_df.shape}\")\n",
    "print(f\"\\nDataset distribution:\")\n",
    "print(combined_df['dataset'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b07f6df",
   "metadata": {},
   "source": [
    "## Feature Extraction: Generate Embeddings\n",
    "\n",
    "Extract embeddings for all texts using the configured BERT model. This may take several minutes depending on dataset size and hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b317204c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing bert-large-cased...\n",
      "Extracting embeddings for GPT-4 (1350 samples)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:27<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings for ChatGPT (1650 samples)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [01:33<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings for DaVinci-002 (900 samples)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:29<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings for DaVinci-003 (1350 samples)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:38<00:00,  2.28s/it]\n"
     ]
    }
   ],
   "source": [
    "from cs7313.embeddings import EmbeddingExtractor\n",
    "\n",
    "print(f\"Initializing {EMBEDDINGS_MODEL}...\")\n",
    "extractor = EmbeddingExtractor(EMBEDDINGS_MODEL)\n",
    "\n",
    "# Extract embeddings for each dataset separately\n",
    "embeddings_dict = {}\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"Extracting embeddings for {name} ({len(df)} samples)...\")\n",
    "    embeddings = extractor(\n",
    "        df[\"text\"].to_numpy(), \n",
    "        batch_size=32, \n",
    "        show_progress=True,\n",
    "        max_length=718,\n",
    "    )\n",
    "    embeddings_dict[name] = embeddings\n",
    "    \n",
    "# Combine all embeddings into a single array\n",
    "ordered_names = list(dataframes.keys())  # same order used to build combined_df\n",
    "combined_embeddings = np.vstack([embeddings_dict[name] for name in ordered_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd1165b",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction\n",
    "\n",
    "Apply multiple dimensionality reduction techniques to visualize the high-dimensional embeddings:\n",
    "\n",
    "- **PCA**: Fast linear method, preserves global variance\n",
    "- **t-SNE**: Non-linear method, good for local structure and cluster visualization\n",
    "- **UMAP**: Fast non-linear method, preserves both local and global structure\n",
    "- **Truncated SVD**: Works well with sparse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3737608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying dimensionality reduction techniques...\n",
      "\n",
      "Applying PCA...\n",
      "Output shape: (5250, 2)\n",
      "Applying t-SNE...\n",
      "Output shape: (5250, 2)\n",
      "Applying UMAP...\n",
      "Output shape: (5250, 2)\n",
      "Applying Truncated SVD...\n",
      "Output shape: (5250, 2)\n",
      "\n",
      "Dimensionality reduction complete!\n"
     ]
    }
   ],
   "source": [
    "from cs7313.features.reduction import (\n",
    "    PCAReducer,\n",
    "    TSNEReducer,\n",
    "    UMAPReducer,\n",
    "    TruncatedSVDReducer,\n",
    ")\n",
    "\n",
    "print(\"Applying dimensionality reduction techniques...\\n\")\n",
    "\n",
    "# Initialize reducers\n",
    "reducers = {\n",
    "    'PCA': PCAReducer(n_components=2, random_state=RANDOM_STATE),\n",
    "    't-SNE': TSNEReducer(n_components=2, perplexity=30, max_iter=1000, random_state=RANDOM_STATE),\n",
    "    'UMAP': UMAPReducer(n_components=2, random_state=RANDOM_STATE),\n",
    "    'Truncated SVD': TruncatedSVDReducer(n_components=2, random_state=RANDOM_STATE),\n",
    "}\n",
    "\n",
    "# Apply reduction to combined dataset\n",
    "reduced_embeddings = {}\n",
    "for method_name, reducer in reducers.items():\n",
    "    print(f\"Applying {method_name}...\")\n",
    "    reduced = reducer(combined_embeddings)\n",
    "    reduced_embeddings[method_name] = reduced\n",
    "    print(f\"Output shape: {reduced.shape}\")\n",
    "\n",
    "print(\"\\nDimensionality reduction complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7241981",
   "metadata": {},
   "source": [
    "## Visualize Dimensionality Reduction Methods\n",
    "\n",
    "Compare different dimensionality reduction techniques overlapping, colored by dataset source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee7b61cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots manually for better legend control\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(\"../docs/assets/\", exist_ok=True)\n",
    "\n",
    "reduction_methods = list(reduced_embeddings.keys())\n",
    "n_cols = 2\n",
    "n_rows = (len(reduction_methods) + n_cols - 1) // n_cols\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=n_rows, \n",
    "    cols=n_cols, \n",
    "    subplot_titles=reduction_methods,\n",
    ")\n",
    "\n",
    "# Color palette for datasets\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f']\n",
    "dataset_names = list(dataframes.keys())\n",
    "\n",
    "for i, (method_name, embeddings) in enumerate(reduced_embeddings.items()):\n",
    "    row = (i // n_cols) + 1\n",
    "    col = (i % n_cols) + 1\n",
    "    \n",
    "    # Add one trace per dataset for proper legend\n",
    "    for j, dataset_name in enumerate(dataset_names):\n",
    "        mask = combined_df['dataset'] == dataset_name\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=embeddings[mask, 0],\n",
    "                y=embeddings[mask, 1],\n",
    "                mode='markers',\n",
    "                name=dataset_name,\n",
    "                text=combined_df.loc[mask, 'hover_text'],\n",
    "                hovertemplate=f'<b>{dataset_name}</b><br><b>Text:</b> %{{text}}<extra></extra>',\n",
    "                marker=dict(size=4, color=colors[j % len(colors)]),\n",
    "                legendgroup=dataset_name,  # Group legends by dataset\n",
    "                showlegend=(i == 0),  # Only show legend for first subplot\n",
    "            ),\n",
    "            row=row, col=col\n",
    "        )\n",
    "\n",
    "fig.update_layout(\n",
    "    width=1980, \n",
    "    height=1080, \n",
    "    showlegend=True,\n",
    "    legend=dict(\n",
    "        title=\"Dataset\",\n",
    "        yanchor=\"top\",\n",
    "        y=0.99,\n",
    "        xanchor=\"left\",\n",
    "        x=1.01\n",
    "    )\n",
    ")\n",
    "# fig.show()\n",
    "\n",
    "# Save figure\n",
    "fig.write_image(\"../docs/assets/dim_reductions.jpg\", width=1980, height=1080)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68390ec3",
   "metadata": {},
   "source": [
    "## Visualize by Demographics\n",
    "\n",
    "Analyze how demographic attributes (gender and race) are distributed in the embedding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df09625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create demographic color mapping\n",
    "if 'demographic' in combined_df.columns:\n",
    "    demographic_categories = combined_df['demographic'].unique()\n",
    "    demographic_colors = {cat: i for i, cat in enumerate(demographic_categories)}\n",
    "    demographic_color_values = combined_df['demographic'].map(demographic_colors)\n",
    "    \n",
    "    # Visualize UMAP with demographic coloring\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    for j, demographic in enumerate(demographic_categories):\n",
    "        mask = combined_df['demographic'] == demographic\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=reduced_embeddings['UMAP'][mask, 0],\n",
    "            y=reduced_embeddings['UMAP'][mask, 1],\n",
    "            mode='markers',\n",
    "            name=demographic,\n",
    "            text=combined_df.loc[mask, 'hover_text'],\n",
    "            hovertemplate='<b>%{fullData.name}</b><br><b>Text:</b> %{text}<extra></extra>',\n",
    "            marker=dict(size=8, opacity=0.6),\n",
    "        ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        # title=\"UMAP Visualization - Colored by Demographics (Gender - Race)\",\n",
    "        xaxis_title=\"UMAP Dimension 1\",\n",
    "        yaxis_title=\"UMAP Dimension 2\",\n",
    "        height=700,\n",
    "        showlegend=True,\n",
    "        legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=1.01)\n",
    "    )\n",
    "    # fig.show()\n",
    "    \n",
    "    # Save figure\n",
    "    fig.write_image(\"../docs/assets/umap_demographics.jpg\", width=1980, height=1080)\n",
    "else:\n",
    "    print(\"Demographic information not available in all datasets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbb58ae",
   "metadata": {},
   "source": [
    "## Clustering Analysis\n",
    "\n",
    "Apply multiple clustering algorithms to identify patterns in the text embeddings. We use UMAP-reduced embeddings as they preserve both local and global structure well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c58a8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying clustering algorithms to UMAP embeddings...\n",
      "\n",
      "Applying K-Means...\n",
      "  Found 5 clusters\n",
      "Applying DBSCAN...\n",
      "  Found 8 clusters\n",
      "Applying Agglomerative...\n",
      "  Found 5 clusters\n",
      "Applying Gaussian Mixture...\n",
      "  Found 5 clusters\n",
      "\n",
      "Clustering complete!\n"
     ]
    }
   ],
   "source": [
    "from cs7313.features.clustering import (\n",
    "    KMeansClustering,\n",
    "    DBSCANClustering,\n",
    "    AgglomerativeClustering,\n",
    "    GaussianMixtureClustering,\n",
    ")\n",
    "\n",
    "print(\"Applying clustering algorithms to UMAP embeddings...\\n\")\n",
    "\n",
    "# Use UMAP embeddings for clustering\n",
    "clustering_data = reduced_embeddings['UMAP']\n",
    "\n",
    "# Initialize clustering algorithms\n",
    "clusterers = {\n",
    "    'K-Means': KMeansClustering(n_clusters=N_CLUSTERS, random_state=RANDOM_STATE),\n",
    "    'DBSCAN': DBSCANClustering(eps=DBSCAN_EPS, min_samples=DBSCAN_MIN_SAMPLES),\n",
    "    'Agglomerative': AgglomerativeClustering(n_clusters=N_CLUSTERS),\n",
    "    'Gaussian Mixture': GaussianMixtureClustering(n_components=N_CLUSTERS, random_state=RANDOM_STATE),\n",
    "}\n",
    "\n",
    "# Apply clustering\n",
    "cluster_labels = {}\n",
    "for method_name, clusterer in clusterers.items():\n",
    "    print(f\"Applying {method_name}...\")\n",
    "    labels = clusterer(clustering_data)\n",
    "    cluster_labels[method_name] = labels\n",
    "    \n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise = list(labels).count(-1) if -1 in labels else 0\n",
    "    \n",
    "    print(f\"  Found {n_clusters} clusters\", end=\"\")\n",
    "    if n_noise > 0:\n",
    "        print(f\" and {n_noise} noise points\")\n",
    "    else:\n",
    "        print()\n",
    "\n",
    "print(\"\\nClustering complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c25175",
   "metadata": {},
   "source": [
    "## Visualize Clustering Results\n",
    "\n",
    "Compare the different clustering algorithms on UMAP-reduced embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "634ce62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots for clustering comparison\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=tuple(f\"{name} (k={N_CLUSTERS})\" if name != 'DBSCAN' else name \n",
    "                        for name in cluster_labels.keys()),\n",
    "    specs=[[{'type': 'scatter'}, {'type': 'scatter'}],\n",
    "           [{'type': 'scatter'}, {'type': 'scatter'}]]\n",
    ")\n",
    "\n",
    "positions = [(1, 1), (1, 2), (2, 1), (2, 2)]\n",
    "\n",
    "for (row, col), (method_name, labels) in zip(positions, cluster_labels.items()):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=clustering_data[:, 0],\n",
    "            y=clustering_data[:, 1],\n",
    "            mode='markers',\n",
    "            text=combined_df['hover_text'],\n",
    "            customdata=combined_df[['dataset']],\n",
    "            hovertemplate='<b>Cluster %{marker.color}</b><br><b>Dataset:</b> %{customdata[0]}<br><b>Text:</b> %{text}<extra></extra>',\n",
    "            marker=dict(size=4, color=labels, colorscale='Viridis', showscale=False),\n",
    "            name=method_name,\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=row, col=col\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    # title_text=\"Comparison of Clustering Algorithms on UMAP Embeddings\"\n",
    "    height=800,\n",
    ")\n",
    "# fig.show()\n",
    "\n",
    "# Save figure\n",
    "fig.write_image(\"../docs/assets/clustering.jpg\", width=1980, height=1080)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fba1b7",
   "metadata": {},
   "source": [
    "## Add Cluster Labels to DataFrames\n",
    "\n",
    "Store cluster assignments for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca21db71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster labels added to dataframe.\n",
      "\n",
      "New columns: ['cluster_k_means', 'cluster_dbscan', 'cluster_agglomerative', 'cluster_gaussian_mixture']\n"
     ]
    }
   ],
   "source": [
    "# Add cluster labels to combined dataframe\n",
    "for method_name, labels in cluster_labels.items():\n",
    "    col_name = f\"cluster_{method_name.lower().replace(' ', '_').replace('-', '_')}\"\n",
    "    combined_df[col_name] = labels\n",
    "\n",
    "print(\"Cluster labels added to dataframe.\")\n",
    "print(f\"\\nNew columns: {[col for col in combined_df.columns if col.startswith('cluster_')]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1326c6e7",
   "metadata": {},
   "source": [
    "## Analyze Cluster Content\n",
    "\n",
    "Examine sample texts from each cluster to understand what patterns the algorithms identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2299e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "K-MEANS CLUSTERING ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "CLUSTER 0 (n=1985 samples)\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Dataset distribution:\n",
      "dataset\n",
      "ChatGPT        672\n",
      "DaVinci-003    454\n",
      "GPT-4          431\n",
      "DaVinci-002    428\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Demographic distribution:\n",
      "demographic\n",
      "W - a Latine            210\n",
      "M - a Latine            208\n",
      "M - a White             207\n",
      "M - an Asian            204\n",
      "W - a White             201\n",
      "W - an Asian            201\n",
      "M - a Middle-Eastern    195\n",
      "W - a Middle-Eastern    195\n",
      "W - a Black             178\n",
      "M - a Black             158\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample texts:\n",
      "\n",
      "  [1] As I stand here looking at my reflection in the mirror, I notice the fair complexion of my skin, characteristic of my White ethnicity. My eyes are a shade of blue, and they often seem to change tones ...\n",
      "\n",
      "  [2] As I glance in the mirror, I see a White man staring back at me. My skin is fair, though not without the occasional freckles scattered across my cheeks and nose. My eyes are a light blue, a hue often ...\n",
      "\n",
      "  [3] As I look in the mirror, I see a reflection of a man with fair skin – some might describe it as pale or even milky. My light-colored, straight hair frames a face that features blue eyes, which are oft...\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "CLUSTER 1 (n=1204 samples)\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Dataset distribution:\n",
      "dataset\n",
      "ChatGPT        376\n",
      "GPT-4          314\n",
      "DaVinci-002    286\n",
      "DaVinci-003    228\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Demographic distribution:\n",
      "demographic\n",
      "M - a Middle-Eastern    224\n",
      "M - an Asian            213\n",
      "M - a Black             211\n",
      "M - a White             210\n",
      "M - a Latine            210\n",
      "W - a White              65\n",
      "W - a Middle-Eastern     28\n",
      "W - a Black              22\n",
      "W - an Asian             20\n",
      "W - a Latine              1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample texts:\n",
      "\n",
      "  [1] A white man is an individual belonging to the Caucasian race, characterized by lighter skin tones that can range from pale to beige, light brown, or olive. His hair color can vary from blonde, brown, ...\n",
      "\n",
      "  [2] A white man refers to an individual who identifies as male and belongs to the Caucasian race, which usually has lighter skin tones. Typically, white men have European ancestry, and their features migh...\n",
      "\n",
      "  [3] A white man typically refers to a male individual of Caucasian or European descent, with lighter skin complexion that can range from pale to light beige or olive. He might have hair colors that vary b...\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "CLUSTER 2 (n=517 samples)\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Dataset distribution:\n",
      "dataset\n",
      "GPT-4          223\n",
      "DaVinci-003    223\n",
      "ChatGPT         70\n",
      "DaVinci-002      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Demographic distribution:\n",
      "demographic\n",
      "N - a White             105\n",
      "N - a Black             104\n",
      "N - an Asian            103\n",
      "N - a Latine            103\n",
      "N - a Middle-Eastern    100\n",
      "W - a White               1\n",
      "W - a Latine              1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample texts:\n",
      "\n",
      "  [1] A white nonbinary person is an individual of Caucasian or European descent who does not identify strictly as male or female. They may feel that they are a mix of both genders or that they don't fit wi...\n",
      "\n",
      "  [2] A white nonbinary person is someone who identifies as neither strictly male nor female and has a Caucasian ethnic background. Their gender identity may fall somewhere on a spectrum between male and fe...\n",
      "\n",
      "  [3] A White nonbinary person is an individual who identifies as nonbinary, which means that they do not exclusively identify as either male or female in terms of their gender. They are also of White or Ca...\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "CLUSTER 3 (n=595 samples)\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Dataset distribution:\n",
      "dataset\n",
      "DaVinci-003    221\n",
      "GPT-4          207\n",
      "ChatGPT        153\n",
      "DaVinci-002     14\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Demographic distribution:\n",
      "demographic\n",
      "N - a White             102\n",
      "N - a Latine            100\n",
      "N - an Asian            100\n",
      "N - a Black              99\n",
      "N - a Middle-Eastern     96\n",
      "M - a Black              51\n",
      "W - a Black              32\n",
      "W - a White               5\n",
      "W - an Asian              5\n",
      "M - a White               3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample texts:\n",
      "\n",
      "  [1] I've always been proud of my deep, rich skin tone and the strong, wavy hair unique to my African heritage. Growing up, I faced the inevitable struggles that came with being a person of color in a prim...\n",
      "\n",
      "  [2] I've always had a relatively easy time blending in with the majority of people in my country. Born and raised in a suburban neighborhood, my middle-class upbringing afforded me a decent education and ...\n",
      "\n",
      "  [3] As a white non-binary person, I exist beyond the traditional gender binary of male or female. I don't easily fit into society's expectations of gender roles and expressions. My pale skin tone highligh...\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "CLUSTER 4 (n=949 samples)\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Dataset distribution:\n",
      "dataset\n",
      "ChatGPT        379\n",
      "DaVinci-003    224\n",
      "GPT-4          175\n",
      "DaVinci-002    171\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Demographic distribution:\n",
      "demographic\n",
      "W - a Latine            208\n",
      "W - a Middle-Eastern    197\n",
      "W - an Asian            194\n",
      "W - a Black             188\n",
      "W - a White             148\n",
      "N - a Middle-Eastern      5\n",
      "M - an Asian              3\n",
      "N - a Latine              2\n",
      "N - an Asian              2\n",
      "N - a Black               1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample texts:\n",
      "\n",
      "  [1] The White woman has a fair complexion with rosy undertones, making her skin appear smooth and glowing. Her hair is long and blonde, with soft waves cascading down to her shoulders. Her eyes are a vivi...\n",
      "\n",
      "  [2] The White woman has fair skin with a light complexion, possibly with freckles scattered across her cheeks and nose. She has striking blue, green, or light brown eyes, framed by long, light-colored eye...\n",
      "\n",
      "  [3] The woman has fair, pale skin with a subtle rosy hue on her cheeks. Her hair is a light shade of blonde or brown, cascading in soft waves around her face. Her eyes are either blue or green, framed by ...\n"
     ]
    }
   ],
   "source": [
    "# Analyze K-Means clusters\n",
    "print(\"=\"*80)\n",
    "print(\"K-MEANS CLUSTERING ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for cluster_id in sorted(set(cluster_labels['K-Means'])):\n",
    "    mask = combined_df['cluster_k_means'] == cluster_id\n",
    "    cluster_data = combined_df[mask]\n",
    "    \n",
    "    print(f\"\\n{'─'*80}\")\n",
    "    print(f\"CLUSTER {cluster_id} (n={sum(mask)} samples)\")\n",
    "    print(f\"{'─'*80}\")\n",
    "    \n",
    "    # Dataset distribution\n",
    "    print(\"\\nDataset distribution:\")\n",
    "    print(cluster_data['dataset'].value_counts())\n",
    "    \n",
    "    # Demographic distribution if available\n",
    "    if 'demographic' in cluster_data.columns:\n",
    "        print(\"\\nDemographic distribution:\")\n",
    "        print(cluster_data['demographic'].value_counts().head(10))\n",
    "    \n",
    "    # Sample texts\n",
    "    print(\"\\nSample texts:\")\n",
    "    for i, text in enumerate(cluster_data['text'].head(3), 1):\n",
    "        print(f\"\\n  [{i}] {text[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94993d5",
   "metadata": {},
   "source": [
    "## Cluster Statistics\n",
    "\n",
    "Compare cluster sizes and characteristics across different algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd2d686b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster sizes by algorithm:\n",
      "   K-Means  DBSCAN  Agglomerative  Gaussian Mixture\n",
      "0   1985.0    2068         1333.0            2072.0\n",
      "1   1204.0    2047         2072.0            1347.0\n",
      "2    517.0      20          517.0             517.0\n",
      "3    595.0     508          820.0             508.0\n",
      "4    949.0     517          508.0             806.0\n",
      "5      NaN      65            NaN               NaN\n",
      "6      NaN       5            NaN               NaN\n",
      "7      NaN      20            NaN               NaN\n",
      "\n",
      "Note: DBSCAN cluster -1 represents noise/outliers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resorting to unclean kill browser.\n"
     ]
    }
   ],
   "source": [
    "# Create cluster size comparison\n",
    "cluster_stats = pd.DataFrame({\n",
    "    method: pd.Series(labels).value_counts().sort_index()\n",
    "    for method, labels in cluster_labels.items()\n",
    "})\n",
    "\n",
    "print(\"Cluster sizes by algorithm:\")\n",
    "print(cluster_stats)\n",
    "print(\"\\nNote: DBSCAN cluster -1 represents noise/outliers\")\n",
    "\n",
    "# Visualize cluster size distributions\n",
    "fig = go.Figure()\n",
    "for col in cluster_stats.columns:\n",
    "    fig.add_trace(go.Bar(\n",
    "        name=col,\n",
    "        x=cluster_stats.index,\n",
    "        y=cluster_stats[col],\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    # title=\"Cluster Size Distribution by Algorithm\",\n",
    "    xaxis_title=\"Cluster ID\",\n",
    "    yaxis_title=\"Number of Points\",\n",
    "    barmode='group',\n",
    "    height=500\n",
    ")\n",
    "# fig.show()\n",
    "\n",
    "# Save figure\n",
    "fig.write_image(\"../docs/assets/cluster_size_distribution.jpg\", width=1980, height=1080)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8b0d2d",
   "metadata": {},
   "source": [
    "## Cross-Dataset Cluster Analysis\n",
    "\n",
    "Analyze how different datasets are distributed across clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14a3aeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means Cluster Distribution Across Datasets:\n",
      "dataset          ChatGPT  DaVinci-002  DaVinci-003  GPT-4   All\n",
      "cluster_k_means                                                \n",
      "0                    672          428          454    431  1985\n",
      "1                    376          286          228    314  1204\n",
      "2                     70            1          223    223   517\n",
      "3                    153           14          221    207   595\n",
      "4                    379          171          224    175   949\n",
      "All                 1650          900         1350   1350  5250\n"
     ]
    }
   ],
   "source": [
    "# Create cross-tabulation for K-Means clusters vs datasets\n",
    "cross_tab = pd.crosstab(\n",
    "    combined_df['cluster_k_means'],\n",
    "    combined_df['dataset'],\n",
    "    margins=True\n",
    ")\n",
    "\n",
    "print(\"K-Means Cluster Distribution Across Datasets:\")\n",
    "print(cross_tab)\n",
    "\n",
    "# Visualize as heatmap\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=cross_tab.iloc[:-1, :-1].values,\n",
    "    x=cross_tab.columns[:-1],\n",
    "    y=cross_tab.index[:-1],\n",
    "    colorscale='Viridis',\n",
    "    text=cross_tab.iloc[:-1, :-1].values,\n",
    "    texttemplate='%{text}',\n",
    "    textfont={\"size\": 10},\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    # title=\"K-Means Cluster Distribution Across Datasets (Heatmap)\",\n",
    "    xaxis_title=\"Dataset\",\n",
    "    yaxis_title=\"Cluster ID\",\n",
    "    height=500\n",
    ")\n",
    "# fig.show()\n",
    "\n",
    "# Save figure\n",
    "fig.write_image(\"../docs/assets/kmeans_dataset_heatmap.jpg\", width=1980, height=1080)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7028b9",
   "metadata": {},
   "source": [
    "## Demographic Bias in Clusters\n",
    "\n",
    "Analyze how demographic attributes are distributed across clusters to identify potential biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b265162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means Cluster Distribution by Demographics:\n",
      "demographic      M - a Black  M - a Latine  M - a Middle-Eastern  M - a White  \\\n",
      "cluster_k_means                                                                 \n",
      "0                        158           208                   195          207   \n",
      "1                        211           210                   224          210   \n",
      "2                          0             0                     0            0   \n",
      "3                         51             2                     0            3   \n",
      "4                          0             0                     1            0   \n",
      "\n",
      "demographic      M - an Asian  N - a Black  N - a Latine  \\\n",
      "cluster_k_means                                            \n",
      "0                         204            6             5   \n",
      "1                         213            0             0   \n",
      "2                           0          104           103   \n",
      "3                           0           99           100   \n",
      "4                           3            1             2   \n",
      "\n",
      "demographic      N - a Middle-Eastern  N - a White  N - an Asian  W - a Black  \\\n",
      "cluster_k_means                                                                 \n",
      "0                                   9            3             5          178   \n",
      "1                                   0            0             0           22   \n",
      "2                                 100          105           103            0   \n",
      "3                                  96          102           100           32   \n",
      "4                                   5            0             2          188   \n",
      "\n",
      "demographic      W - a Latine  W - a Middle-Eastern  W - a White  W - an Asian  \n",
      "cluster_k_means                                                                 \n",
      "0                         210                   195          201           201  \n",
      "1                           1                    28           65            20  \n",
      "2                           1                     0            1             0  \n",
      "3                           0                     0            5             5  \n",
      "4                         208                   197          148           194  \n",
      "\n",
      "Percentage distribution within each cluster:\n",
      "demographic      M - a Black  M - a Latine  M - a Middle-Eastern  M - a White  \\\n",
      "cluster_k_means                                                                 \n",
      "0                       7.96         10.48                  9.82        10.43   \n",
      "1                      17.52         17.44                 18.60        17.44   \n",
      "2                       0.00          0.00                  0.00         0.00   \n",
      "3                       8.57          0.34                  0.00         0.50   \n",
      "4                       0.00          0.00                  0.11         0.00   \n",
      "\n",
      "demographic      M - an Asian  N - a Black  N - a Latine  \\\n",
      "cluster_k_means                                            \n",
      "0                       10.28         0.30          0.25   \n",
      "1                       17.69         0.00          0.00   \n",
      "2                        0.00        20.12         19.92   \n",
      "3                        0.00        16.64         16.81   \n",
      "4                        0.32         0.11          0.21   \n",
      "\n",
      "demographic      N - a Middle-Eastern  N - a White  N - an Asian  W - a Black  \\\n",
      "cluster_k_means                                                                 \n",
      "0                                0.45         0.15          0.25         8.97   \n",
      "1                                0.00         0.00          0.00         1.83   \n",
      "2                               19.34        20.31         19.92         0.00   \n",
      "3                               16.13        17.14         16.81         5.38   \n",
      "4                                0.53         0.00          0.21        19.81   \n",
      "\n",
      "demographic      W - a Latine  W - a Middle-Eastern  W - a White  W - an Asian  \n",
      "cluster_k_means                                                                 \n",
      "0                       10.58                  9.82        10.13         10.13  \n",
      "1                        0.08                  2.33         5.40          1.66  \n",
      "2                        0.19                  0.00         0.19          0.00  \n",
      "3                        0.00                  0.00         0.84          0.84  \n",
      "4                       21.92                 20.76        15.60         20.44  \n"
     ]
    }
   ],
   "source": [
    "if 'demographic' in combined_df.columns:\n",
    "    # Cross-tabulation for demographics vs clusters\n",
    "    demo_cross_tab = pd.crosstab(\n",
    "        combined_df['cluster_k_means'],\n",
    "        combined_df['demographic'],\n",
    "    )\n",
    "    \n",
    "    print(\"K-Means Cluster Distribution by Demographics:\")\n",
    "    print(demo_cross_tab)\n",
    "    \n",
    "    # Calculate percentages within each cluster\n",
    "    demo_percentages = demo_cross_tab.div(demo_cross_tab.sum(axis=1), axis=0) * 100\n",
    "    \n",
    "    print(\"\\nPercentage distribution within each cluster:\")\n",
    "    print(demo_percentages.round(2))\n",
    "    \n",
    "    # Visualize as stacked bar chart\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    for demographic in demo_percentages.columns:\n",
    "        fig.add_trace(go.Bar(\n",
    "            name=demographic,\n",
    "            x=demo_percentages.index,\n",
    "            y=demo_percentages[demographic],\n",
    "        ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        # title=\"Demographic Distribution within K-Means Clusters (%)\",\n",
    "        xaxis_title=\"Cluster ID\",\n",
    "        yaxis_title=\"Percentage\",\n",
    "        barmode='stack',\n",
    "        height=500\n",
    "    )\n",
    "    # fig.show()\n",
    "    \n",
    "    # Save figure\n",
    "    fig.write_image(\"../docs/assets/demographic_distribution_clusters.jpg\", width=1980, height=1080)\n",
    "else:\n",
    "    print(\"Demographic information not available for bias analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d199b19c",
   "metadata": {},
   "source": [
    "## Export Results\n",
    "\n",
    "Save the analyzed data with cluster assignments for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "851e8394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: ../data/combined_analysis_results.csv\n",
      "PCA embeddings saved to: ../data/embeddings_pca.npy\n",
      "t-SNE embeddings saved to: ../data/embeddings_t_sne.npy\n",
      "UMAP embeddings saved to: ../data/embeddings_umap.npy\n",
      "Truncated SVD embeddings saved to: ../data/embeddings_truncated_svd.npy\n"
     ]
    }
   ],
   "source": [
    "# Save combined dataframe with cluster labels\n",
    "output_path = \"../data/combined_analysis_results.csv\"\n",
    "combined_df.to_csv(output_path, index=False)\n",
    "print(f\"Results saved to: {output_path}\")\n",
    "\n",
    "# Save reduced embeddings\n",
    "for method_name, embeddings in reduced_embeddings.items():\n",
    "    embed_path = f\"../data/embeddings_{method_name.lower().replace(' ', '_').replace('-', '_')}.npy\"\n",
    "    np.save(embed_path, embeddings)\n",
    "    print(f\"{method_name} embeddings saved to: {embed_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa430c3",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "\n",
    "Final summary of the comprehensive analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9003b29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPREHENSIVE ANALYSIS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Datasets Analyzed: 4\n",
      "  - GPT-4: 1350 samples\n",
      "  - ChatGPT: 1650 samples\n",
      "  - DaVinci-002: 900 samples\n",
      "  - DaVinci-003: 1350 samples\n",
      "\n",
      "Total Samples: 5250\n",
      "Embedding Model: bert-large-cased\n",
      "Embedding Dimensions: 1024\n",
      "\n",
      "Dimensionality Reduction Methods: 4\n",
      "  - PCA\n",
      "  - t-SNE\n",
      "  - UMAP\n",
      "  - Truncated SVD\n",
      "\n",
      "Clustering Algorithms: 4\n",
      "  - K-Means: 5 clusters\n",
      "  - DBSCAN: 8 clusters\n",
      "  - Agglomerative: 5 clusters\n",
      "  - Gaussian Mixture: 5 clusters\n",
      "\n",
      "Unique Demographics: 15\n",
      "Most common demographics:\n",
      "demographic\n",
      "M - a White             420\n",
      "M - a Black             420\n",
      "M - an Asian            420\n",
      "M - a Middle-Eastern    420\n",
      "M - a Latine            420\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n",
      "Analysis complete! Review the visualizations above for insights.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nDatasets Analyzed: {len(dataframes)}\")\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"  - {name}: {len(df)} samples\")\n",
    "\n",
    "print(f\"\\nTotal Samples: {len(combined_df)}\")\n",
    "print(f\"Embedding Model: {EMBEDDINGS_MODEL}\")\n",
    "print(f\"Embedding Dimensions: {combined_embeddings.shape[1]}\")\n",
    "\n",
    "print(f\"\\nDimensionality Reduction Methods: {len(reduced_embeddings)}\")\n",
    "for method in reduced_embeddings.keys():\n",
    "    print(f\"  - {method}\")\n",
    "\n",
    "print(f\"\\nClustering Algorithms: {len(cluster_labels)}\")\n",
    "for method, labels in cluster_labels.items():\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    print(f\"  - {method}: {n_clusters} clusters\")\n",
    "\n",
    "if 'demographic' in combined_df.columns:\n",
    "    print(f\"\\nUnique Demographics: {combined_df['demographic'].nunique()}\")\n",
    "    print(f\"Most common demographics:\")\n",
    "    print(combined_df['demographic'].value_counts().head(5))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Analysis complete! Review the visualizations above for insights.\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs7313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
